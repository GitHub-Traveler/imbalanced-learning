{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T17:44:10.198030Z","iopub.status.busy":"2024-03-24T17:44:10.197618Z","iopub.status.idle":"2024-03-24T17:44:17.065325Z","shell.execute_reply":"2024-03-24T17:44:17.064247Z","shell.execute_reply.started":"2024-03-24T17:44:10.198004Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms.v2 as v2\n","import torchvision.datasets as datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T18:05:44.314942Z","iopub.status.busy":"2024-03-24T18:05:44.314493Z","iopub.status.idle":"2024-03-24T18:05:44.320260Z","shell.execute_reply":"2024-03-24T18:05:44.319127Z","shell.execute_reply.started":"2024-03-24T18:05:44.314908Z"},"trusted":true},"outputs":[],"source":["torch.set_default_device('cpu')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["transform_func = v2.Compose([\n","    v2.ToImage(), \n","    v2.ToDtype(torch.float32, scale=True)\n","])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T18:05:53.157222Z","iopub.status.busy":"2024-03-24T18:05:53.156803Z","iopub.status.idle":"2024-03-24T18:05:53.250412Z","shell.execute_reply":"2024-03-24T18:05:53.249332Z","shell.execute_reply.started":"2024-03-24T18:05:53.157188Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar100_dataset/cifar-100-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 169001437/169001437 [36:39<00:00, 76843.72it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["Extracting cifar100_dataset/cifar-100-python.tar.gz to cifar100_dataset\n","Files already downloaded and verified\n"]}],"source":["mnist_trainset = datasets.CIFAR100(root='cifar100_dataset', train=True, download=True, transform=transform_func)\n","mnist_testset = datasets.CIFAR100(root='cifar100_dataset', train=False, download=True, transform=transform_func)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["mnist_train_dl = torch.utils.data.DataLoader(mnist_trainset, shuffle = True, num_workers=16, batch_size = 64, pin_memory=True, prefetch_factor=4)\n","mnist_test_dl = torch.utils.data.DataLoader(mnist_testset, shuffle = False, num_workers=16, batch_size = len(mnist_testset))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class DeepConvNet(nn.Module):\n","    class ConvBlock(nn.Module):\n","        def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation=1):\n","            super().__init__()\n","            self.module = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation=dilation),    \n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU()\n","            )\n","        \n","        def forward(self, input):\n","            return self.module(input)\n","        \n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = self.ConvBlock(3, 16, 7)\n","        self.conv2 = self.ConvBlock(16, 32, 3, 2)\n","        self.conv3 = self.ConvBlock(32, 64, 3, 2, 1)\n","        self.conv4 = self.ConvBlock(64, 128, 3, 2, 1)\n","        self.flatten = nn.Flatten()\n","        self.linear = nn.Sequential(\n","            nn.Linear(1152, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 100),\n","            nn.Softmax(dim=1)\n","            )\n","    def forward(self, X):\n","        hidden = self.conv1(X)\n","        hidden = self.conv2(hidden)\n","        hidden = self.conv3(hidden)\n","        hidden = self.conv4(hidden)\n","        hidden = self.flatten(hidden)\n","        return self.linear(hidden)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [01:19<00:00,  7.91s/it]\n"]}],"source":["from tqdm import tqdm\n","model = DeepConvNet().to('cuda')\n","loss_fn = nn.CrossEntropyLoss().to('cuda')\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","\n","num_epoch = 10\n","for i in tqdm(range(num_epoch)):\n","    for inputs, labels in mnist_train_dl:\n","        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n","        optimizer.zero_grad(set_to_none=True)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","import numpy as np\n","inputs_test, labels_test = next(iter(mnist_test_dl))\n","inputs_test = inputs_test.cuda()\n","output = model(inputs_test).cpu().detach().numpy()\n","labels_test = labels_test.cpu().detach().numpy()\n","output = np.argmax(output, axis = 1)\n","print(classification_report(labels_test, output))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["1004132"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["sum(p.numel() for p in model.parameters())"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------+------------+\n","|        Modules        | Parameters |\n","+-----------------------+------------+\n","| conv1.module.0.weight |    2352    |\n","|  conv1.module.0.bias  |     16     |\n","| conv1.module.1.weight |     16     |\n","|  conv1.module.1.bias  |     16     |\n","| conv2.module.0.weight |    4608    |\n","|  conv2.module.0.bias  |     32     |\n","| conv2.module.1.weight |     32     |\n","|  conv2.module.1.bias  |     32     |\n","| conv3.module.0.weight |   18432    |\n","|  conv3.module.0.bias  |     64     |\n","| conv3.module.1.weight |     64     |\n","|  conv3.module.1.bias  |     64     |\n","| conv4.module.0.weight |   73728    |\n","|  conv4.module.0.bias  |    128     |\n","| conv4.module.1.weight |    128     |\n","|  conv4.module.1.bias  |    128     |\n","|    linear.0.weight    |   589824   |\n","|     linear.0.bias     |    512     |\n","|    linear.2.weight    |   262144   |\n","|     linear.2.bias     |    512     |\n","|    linear.4.weight    |   51200    |\n","|     linear.4.bias     |    100     |\n","+-----------------------+------------+\n","Total Trainable Params: 1004132\n"]},{"data":{"text/plain":["1004132"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from prettytable import PrettyTable\n","\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad:\n","            continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params += params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params\n","    \n","count_parameters(model)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
