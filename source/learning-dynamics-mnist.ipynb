{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T17:44:10.198030Z","iopub.status.busy":"2024-03-24T17:44:10.197618Z","iopub.status.idle":"2024-03-24T17:44:17.065325Z","shell.execute_reply":"2024-03-24T17:44:17.064247Z","shell.execute_reply.started":"2024-03-24T17:44:10.198004Z"},"trusted":true},"outputs":[],"source":["import torch, torch.utils.data\n","import torch.nn as nn\n","import torchvision.transforms.v2 as v2\n","import torchvision.datasets as datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T18:05:44.314942Z","iopub.status.busy":"2024-03-24T18:05:44.314493Z","iopub.status.idle":"2024-03-24T18:05:44.320260Z","shell.execute_reply":"2024-03-24T18:05:44.319127Z","shell.execute_reply.started":"2024-03-24T18:05:44.314908Z"},"trusted":true},"outputs":[],"source":["torch.set_default_device('cpu')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["transform_func = v2.Compose([\n","    v2.ToImage(), \n","    v2.ToDtype(torch.float32, scale=True),\n","])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T18:05:53.157222Z","iopub.status.busy":"2024-03-24T18:05:53.156803Z","iopub.status.idle":"2024-03-24T18:05:53.250412Z","shell.execute_reply":"2024-03-24T18:05:53.249332Z","shell.execute_reply.started":"2024-03-24T18:05:53.157188Z"},"trusted":true},"outputs":[],"source":["mnist_trainset = datasets.MNIST(root='mnist_dataset', train=True, download=True, transform=transform_func)\n","mnist_testset = datasets.MNIST(root='mnist_dataset', train=False, download=True, transform=transform_func)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["mnist_train_dl = torch.utils.data.DataLoader(mnist_trainset, shuffle = True, num_workers=16, batch_size = 512, pin_memory=True, prefetch_factor=4)\n","mnist_test_dl = torch.utils.data.DataLoader(mnist_testset, shuffle = False, num_workers=4, batch_size = len(mnist_testset))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class DeepConvNet(nn.Module):\n","    class ConvBlock(nn.Module):\n","        def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation=1):\n","            super().__init__()\n","            self.module = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation=dilation),    \n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU()\n","            )\n","        \n","        def forward(self, input):\n","            return self.module(input)\n","        \n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = self.ConvBlock(1, 16, 7)\n","        self.conv2 = self.ConvBlock(16, 32, 3, 2)\n","        self.conv3 = self.ConvBlock(32, 64, 3, 2, 1)\n","        self.conv4 = self.ConvBlock(64, 128, 3, 2, 1)\n","        self.flatten = nn.Flatten()\n","        self.linear = nn.Sequential(\n","            nn.Linear(1152, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 10),\n","            nn.Softmax(dim=1)\n","            )\n","    def forward(self, X):\n","        hidden = self.conv1(X)\n","        hidden = self.conv2(hidden)\n","        hidden = self.conv3(hidden)\n","        hidden = self.conv4(hidden)\n","        hidden = self.flatten(hidden)\n","        return self.linear(hidden)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["%load_ext line_profiler"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:16<00:00,  1.66s/it]\n"]}],"source":["from tqdm import tqdm\n","model = DeepConvNet().to('cuda')\n","loss_fn = nn.CrossEntropyLoss().to('cuda')\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","num_epoch = 10\n","\n","for i in tqdm(range(num_epoch)):\n","    for inputs, labels in mnist_train_dl:\n","        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n","        optimizer.zero_grad(set_to_none=True)\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00       980\n","           1       0.99      1.00      0.99      1135\n","           2       1.00      0.99      0.99      1032\n","           3       0.98      1.00      0.99      1010\n","           4       0.99      0.99      0.99       982\n","           5       0.99      0.99      0.99       892\n","           6       0.99      0.99      0.99       958\n","           7       0.99      0.98      0.99      1028\n","           8       0.99      0.99      0.99       974\n","           9       0.98      0.99      0.99      1009\n","\n","    accuracy                           0.99     10000\n","   macro avg       0.99      0.99      0.99     10000\n","weighted avg       0.99      0.99      0.99     10000\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","import numpy as np\n","inputs_test, labels_test = next(iter(mnist_test_dl))\n","inputs_test = inputs_test.cuda()\n","output = model(inputs_test).cpu().detach().numpy()\n","labels_test = labels_test.cpu().detach().numpy()\n","output = np.argmax(output, axis = 1)\n","print(classification_report(labels_test, output))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["174474"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["sum(p.numel() for p in model.parameters())"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------+------------+\n","|        Modules        | Parameters |\n","+-----------------------+------------+\n","| conv1.module.0.weight |    784     |\n","|  conv1.module.0.bias  |     16     |\n","| conv1.module.1.weight |     16     |\n","|  conv1.module.1.bias  |     16     |\n","| conv2.module.0.weight |    4608    |\n","|  conv2.module.0.bias  |     32     |\n","| conv2.module.1.weight |     32     |\n","|  conv2.module.1.bias  |     32     |\n","| conv3.module.0.weight |   18432    |\n","|  conv3.module.0.bias  |     64     |\n","| conv3.module.1.weight |     64     |\n","|  conv3.module.1.bias  |     64     |\n","| conv4.module.0.weight |   73728    |\n","|  conv4.module.0.bias  |    128     |\n","| conv4.module.1.weight |    128     |\n","|  conv4.module.1.bias  |    128     |\n","|    linear.0.weight    |   73728    |\n","|     linear.0.bias     |     64     |\n","|    linear.2.weight    |    2048    |\n","|     linear.2.bias     |     32     |\n","|    linear.4.weight    |    320     |\n","|     linear.4.bias     |     10     |\n","+-----------------------+------------+\n","Total Trainable Params: 174474\n"]},{"data":{"text/plain":["174474"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from prettytable import PrettyTable\n","\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad:\n","            continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params += params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params\n","    \n","count_parameters(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test for multiprocessing\n","import torch.multiprocessing as mp\n","\n","def train(model):\n","    # Construct data_loader, optimizer, etc.\n","    for data, labels in mnist_train_dl:\n","        optimizer.zero_grad()\n","        loss_fn(model(data), labels).backward()\n","        optimizer.step()  # This will update the shared parameters\n","\n","if __name__ == '__main__':\n","    num_processes = 4\n","    model = DeepConvNet()\n","    # NOTE: this is required for the ``fork`` method to work\n","    model.share_memory()\n","    processes = []\n","    for rank in range(num_processes):\n","        p = mp.Process(target=train, args=(model,))\n","        p.start()\n","        processes.append(p)\n","    for p in processes:\n","        p.join()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
